#! /usr/bin/env python
# data_muncher.py - Write data in .h5 files from DFS runs in easily readable 
# formats Copyright (C) 2015 Matteo Tiberti <matteo.tiberti@gmail.com>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/li.censes/>.


intro = """data_muncher reads and digests a HDF5 binary format data file 
written by dfs and writes files in the current directory that are easier to 
access and read. It saves numerical data types as .npz numpy-readable files or
text files and structural data as .dcd trajectory files. Depending on what is 
requested, data_muncher can write a huge number of files that take big amounts 
of disk space, so be careful for what you ask for :)"""

outro = """data_muncher accepts as argument just a .h5 file written by dfs. By
default, it writes several user-readable files with user-friendly names. Option
-w works like option -w of dfs, but in this case it allows the user to select
what should be extracted from the .h5 file. The following keywords are 
accepted:

* force_vectors: the force vectors used in Linear Response Theory
* displacements: atomic displacements induced by the force vectors
* displacements_after_fit: atomic displacements between the perturbed and non-
perturbed structure after least-square fitting before them has been 
performed. Only meaningful if fitting has been performed.
* perturbed_coordinates: atomic coordinates of the original structure to which
atomic displacements have been applied. 
* fitted_perturbed_coordinates: atomic coordinates of the original structure to 
which atomic displacements and least square fitting have been applied. Only 
meaningful if fitting has been performed.
* score_matrix: Rescuability score matrix
* raw_score_matrix: score matrix per every residue pair, before the final R 
value is calculated (see the paper for details)
* pm_cdm: conformational distance values for application of a single force on
the considered pathogenic residue
* sm_cdm: conformational distance values for the application of the forces on
the pathogenic mutation site and the secondary site
* conformational_distance_matrixes: both pm_cdm and sm_cdm
* scaling_factors: scaling factors used for force magnitudes
* max_score_perturbed_coordinates: writes a PDB file with the coordinates 
(after perturbation) of only the structure generated with the best-scoring 
pair of forces, together with the relative single-force perturbation
* max_score_fitted_perturbed_coordinates: writes a PDB file with the 
coordinates (after perturbation and least-square fitting) of only the 
structure generated with the best-scoring pair of forces, together with the 
relative single-force perturbation
* all: all of the above

Naturally, information can only be written to output files if it is present in 
the HDF5 compressed file to begin with. Notice that some options have meaning
only if fitting has been performed - meaning that they will return 0-filled 
arrays or coordinate files if they were not really used in dfs.

Option -p (which is the name of the PDB file used to run dfs) is required only
if structural data needs to be written.

Option -t, if used, switches the use of .npz file to plain text files, which
take up more disk space.

Option -d can be used to tune the number of decimal places to be written in
the file (must be 0 or positive).

Example:

    data_muncher -w all_available -t -d 3 ../fixed_force_details.h5 \
    -p ../original.pdb
"""

import os
import h5py
import numpy as np
import logging as log
from dfsutils import DF, DR, F_DR, RAW_SCORES, P_XYZ, FP_XYZ
import prody

def traverse_tree(fh, current="/", data_types=[]):
    if not data_types:
        yield None
        return

    this_keys = filter(unicode.isdigit, fh[current].keys())

    for key in this_keys:
        for t in traverse_tree(fh, current=os.path.join(current,key), data_types=data_types):
            yield t

    for d in data_types:
        if d in fh[current].keys():
            yield (current, d, np.array(fh[current][d]))

def traverse_tree_best(fh, data_type, current="/"):
    if data_type == MAX_SCORE_FP_XYZ:
        coord_type = FP_XYZ
    elif data_type == MAX_SCORE_P_XYZ:
        coord_type = P_XYZ
    else:
        raise TypeError

    this_keys = filter(unicode.isdigit, fh[current].keys())

    for key in this_keys:
        for t in traverse_tree_best(fh,
                                    data_type = data_type,
                                    current=os.path.join(current,key)):
            yield t

    try:
        this_rs = np.array(fh[current][RAW_SCORES])
    except:
        yield None
        return

    current_ref = current.split("/")[1]

    this_coords_ref = np.array(fh[current_ref][coord_type])
    this_coords = np.array(fh[current][coord_type])

    n_elms = int(np.sqrt(this_coords.shape[0]))

    where = np.array(np.where(this_rs == np.max(this_rs)))
    where_idx = where[0][0]*n_elms + where[1][0]

    max_coords = this_coords[where_idx,:,:]
    ref_max_coords = this_coords_ref[where_idx,:,:]

    all_coords = np.array([ref_max_coords, max_coords])

    yield (current, data_type, all_coords)

def write_data(structure, atoms, atom_indices, d, fmt="%.5f", highest=False, lowest=False):
    current, data_type, data = d
    
    if current == '/':
        return

    this_idxs = map(int, current.split("/")[1:])
    #print np.where(atom_indices==this_idxs[0])[0]
    #print atoms.getIndices()[np.where(atom_indices==idx)[0]
    
    idx_matching = []
    for idx in this_idxs:
        idx_matching.append( atoms.getIndices()[np.where(atom_indices==idx)[0]][0] )

    this_atoms = [ structure[s] for s in idx_matching ]

    label = ",".join(["%s-%s%d" % (a.getChid(), a.getResname(), a.getResnum()) for a in this_atoms])

    if data_type in [DF, DR, F_DR, RAW_SCORES, ref_CD, dfs_CD]:
        if data_type == DF:
            fname = "force_vectors_%s.%s" % (label, num_ext)
    
        elif data_type == DR:
            fname = "displacements_%s.%s" % (label, num_ext)
    
        elif data_type == F_DR:
            fname = "fitted_displacements_%s.%s" % (label, num_ext)

        elif data_type == RAW_SCORES:
            fname = "raw_scores_%s.%s" % (label, num_ext)

        elif data_type == ref_CD:
            fname = "reference_cd_%s.%s" % (label, num_ext)

        elif data_type == dfs_CD:
            fname = "dfs_cd_%s.%s" % (label, num_ext)
            
        np.savetxt(fname, data, fmt=decimal_fmt)

    elif data_type in [P_XYZ, FP_XYZ]:
        if data_type == P_XYZ:
            fname = "displaced_structures_%s.dcd" % label

        elif data_type == FP_XYZ:
            fname = "fitted_displaced_structures_%s.dcd" % label

        ensemble = prody.Ensemble()

        lendata = int(np.sqrt(len(data)))    
        for i in range(lendata):
            for j in range(lendata):
                ensemble.addCoordset(data[j*lendata+i])

        prody.writeDCD(fname, ensemble)

    elif data_type in [MAX_SCORE_P_XYZ, MAX_SCORE_FP_XYZ]:

        if data_type == MAX_SCORE_P_XYZ:
            fname = "displaced_structures_%s_max.pdb" % label
            fname_ref = "displaced_structures_%s_max_ref.pdb" % label

        elif data_type == MAX_SCORE_FP_XYZ:
            fname = "fitted_displaced_structures_%s_max.pdb" % label
            fname_ref = "fitted_displaced_structures_%s_max_ref.pdb" % label

        this_structure = structure.copy()
        this_structure_ref = structure.copy()

        this_structure_ref.setCoords(data[0])
        this_structure.setCoords(data[1])

        prody.writePDB(fname_ref, this_structure_ref)
        prody.writePDB(fname, this_structure)


if __name__ == "__main__":

    import argparse
    from argparse import RawTextHelpFormatter    

    ALL = "all"
    ALL_AVAILABLE="all_available"
    MAX_SCORE_P_XYZ = "max_score_perturbed_coordinates"
    MAX_SCORE_FP_XYZ = "max_score_fitted_perturbed_coordinates"
    SCORES = "score_matrix"
    ref_CD = "pm_cdm"
    dfs_CD = "sm_cdm"
    SF = "scaling_factors"
    
    data_types =    [
                        ALL,
                        ALL_AVAILABLE,
                        DF,
                        DR,
                        F_DR,
                        P_XYZ,
                        FP_XYZ,
                        SCORES,
                        RAW_SCORES,
                        MAX_SCORE_P_XYZ,
                        MAX_SCORE_FP_XYZ,
                        SF
                    ]

    argparser = argparse.ArgumentParser(description=intro,
                                        epilog=outro,
                                        formatter_class=RawTextHelpFormatter)
                                     
    argparser.add_argument("HDF5", type=str, help="input HDF5 file")
    argparser.add_argument("-p", "--pdb", type=str, dest="PDB", 
                           help="Original PDB structure", default=None)
    argparser.add_argument("-w", "--write", dest="data_types", nargs='*', 
                           type=str, choices=data_types, help="Choose which\
                           data should be saved in the output file. 'all' \
                           just saves everything is available.", 
                           default=None)
    argparser.add_argument("-t", "--textual", dest="use_dat", 
                           default=False, action='store_true', help="Write \
                           data in simple text format instead of npz when\
                           possible.")
    argparser.add_argument("-d", "--decimal", dest="decimal", type=int, 
                           default=3, action='store', help="Number of decimal\
                           places to be used in writing files")

    args = argparser.parse_args()

    if args.decimal < 0:
        log.error("Option -d must be 0 or positive. Exiting ...")
        exit(1)

    decimal_fmt = "%%.%df" % args.decimal

    try:
        hf = h5py.File(args.HDF5, 'r')
    except:
        log.error("HDF5 file not readable or wrong format. Exiting...")
        exit(1)

    print "File %s metadata:" % args.HDF5
    for k,v in hf.attrs.iteritems():
        k += ":"
        print "\t%s%s" %  (k.ljust(23),v)
        
    available_data = hf.attrs['available_data'].split(",")

    if args.use_dat:
        num_ext = "dat"
    else:
        num_ext = "npz"

    if args.data_types is None:
        exit(0)
    elif ALL in args.data_types:
        if len(args.data_types) > 1:
            log.warning("all was specified in option --write, together with\
others; all will be used.")
        this_data_types = data_types[1:]
    elif ALL_AVAILABLE in data_types:
        this_data_types = available_data
    else:
        this_data_types = args.data_types
        
    log.basicConfig(level=log.DEBUG)

    sf_path = "/%s" % SF

    if sf_path in hf and SF in this_data_types:
        sf = 1.0/np.array(hf[sf_path])
        sf_shape = np.int(np.sqrt(sf.shape[1]))
        np.savetxt("scaling_factors.%s" % num_ext, sf[:,0:sf_shape], fmt=decimal_fmt)
        this_data_types.remove(SF)
        

    if MAX_SCORE_P_XYZ in this_data_types and (RAW_SCORES not in available_data or P_XYZ not in available_data):
        log.error("%s requires %s and %s to be present in details file. Exiting ..." % (MAX_SCORE_P_XYZ, RAW_SCORES, P_XYZ))
        exit(1)
    if MAX_SCORE_FP_XYZ in this_data_types and (RAW_SCORES not in available_data or FP_XYZ not in available_data):
        log.error("%s requires %s and %s to be present in details file. Exiting ..." % (MAX_SCORE_FP_XYZ, RAW_SCORES, FP_XYZ))
        exit(1)

    # 1. Parse PDB (if required)
    if P_XYZ in this_data_types or FP_XYZ in this_data_types or MAX_SCORE_P_XYZ in this_data_types or MAX_SCORE_FP_XYZ in this_data_types:
        if not args.PDB:
            log.error("You need to specify a PDB file to write structure-based information. Exiting...")
            exit(1)
        else:
            try:
                structure = prody.parsePDB(args.PDB)
            except:
                log.error("Couldn't parse your model file (%s); Exiting..." % args.PDB)
                exit(1)

        # 2. select atoms for building the model
        try:
            atoms = structure.select(hf.attrs['atom_selection'])
    
        except prody.SelectionError:
            log.error("Your selection string was invalid. Exiting...")
            exit(1)
        if not atoms:
            log.error("Your selection string resulted in no atoms being selected in your structure. Exiting...")
            exit(1)
        if len(atoms) < 2:
            log.error("Your selection string resulted in less than two atoms being selected in your structure. Exiting...")
            exit(1)

    atom_indices = atoms.getResindices()

    if MAX_SCORE_P_XYZ in this_data_types:
        for d in traverse_tree_best(hf, data_type = MAX_SCORE_P_XYZ):
            if d:
                write_data(structure, atoms, atom_indices, d, highest=True, lowest=False)
        this_data_types.remove(MAX_SCORE_P_XYZ)

    if MAX_SCORE_FP_XYZ in this_data_types:
        for d in traverse_tree_best(hf, data_type = MAX_SCORE_FP_XYZ):
            if d:
                write_data(structure, atoms, atom_indices, d, highest=True, lowest=False)
        this_data_types.remove(MAX_SCORE_FP_XYZ)                

    if this_data_types:
        for d in traverse_tree(hf, data_types = this_data_types):
            write_data(structure, atoms, atom_indices, d)
